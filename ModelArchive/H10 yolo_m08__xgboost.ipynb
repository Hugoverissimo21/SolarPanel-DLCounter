{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideia: usar xgboost + output to yolo do modelo08 + metadata das images para fazer a contagem + rbg\n",
    "\n",
    "razao: corrigir erros sistematicos do modelo08 que possam ser causados qnd a imagem Ã© ... *metadata* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB5\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_origin</th>\n",
       "      <th>img_placement</th>\n",
       "      <th>nr_boil</th>\n",
       "      <th>polygons_boil</th>\n",
       "      <th>nr_pan</th>\n",
       "      <th>polygons_pan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>IDiannr</td>\n",
       "      <td>S</td>\n",
       "      <td>S-unknown</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[(247.1167192429022, 342.61654135338347), (16...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       img_id img_origin img_placement nr_boil  \\\n",
       "1445  IDiannr          S     S-unknown     [1]   \n",
       "\n",
       "                                          polygons_boil nr_pan polygons_pan  \n",
       "1445  [[(247.1167192429022, 342.61654135338347), (16...     []           []  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_pickle('Model_Train.pkl')\n",
    "df_val = pd.read_pickle('Model_Val.pkl')\n",
    "\n",
    "df_train.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hot_encod_img_placement(df):\n",
    "    extra_features_all = []\n",
    "    for i, row in df.iterrows():\n",
    "        extra_features = []\n",
    "        if row[\"img_placement\"] == \"roof\":\n",
    "            extra_features += [1, 0, 0, 0]\n",
    "        elif row[\"img_placement\"] == \"r_openspace\":\n",
    "            extra_features += [0, 1, 0, 0]\n",
    "        elif row[\"img_placement\"] == \"openspace\":\n",
    "            extra_features += [0, 0, 1, 0]\n",
    "        elif row[\"img_placement\"] == \"S-unknown\":\n",
    "            extra_features += [0, 0, 0, 1]\n",
    "        else:\n",
    "            extra_features += [0, 0, 0, 0]\n",
    "        if row[\"img_origin\"] == \"D\":\n",
    "            extra_features += [1, 0]\n",
    "        elif row[\"img_origin\"] == \"S\":\n",
    "            extra_features += [0, 1]\n",
    "        else:\n",
    "            extra_features += [0, 0] \n",
    "        extra_features_all.append(extra_features)\n",
    "    \n",
    "    df[\"more_features\"] = extra_features_all\n",
    "\n",
    "    df.drop(columns=[\"img_origin\"], inplace=True)\n",
    "    df.drop(columns=[\"img_placement\"], inplace=True)\n",
    "\n",
    "hot_encod_img_placement(df_train)\n",
    "hot_encod_img_placement(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>nr_boil</th>\n",
       "      <th>polygons_boil</th>\n",
       "      <th>nr_pan</th>\n",
       "      <th>polygons_pan</th>\n",
       "      <th>more_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDUXSjTNlUQ59</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[14, 16]</td>\n",
       "      <td>[[(228.0551181102362, 277.6509186351706), (231...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDln9t3L</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[(263.552, 259.584), (316.032, 237.056), (344...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDdLAJld1z</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[[(313.9878787878788, 384.1294236602629), (339...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID6g6IV</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[(246.784, 171.17866666666666), (283.648, 156...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDrxyCyN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[(203.37777777777777, 235.99198396793588), (1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_id       nr_boil  \\\n",
       "0  IDUXSjTNlUQ59            []   \n",
       "1       IDln9t3L            []   \n",
       "2     IDdLAJld1z  [1, 1, 1, 1]   \n",
       "3        ID6g6IV            []   \n",
       "4       IDrxyCyN           [1]   \n",
       "\n",
       "                                       polygons_boil    nr_pan  \\\n",
       "0                                                 []  [14, 16]   \n",
       "1                                                 []       [2]   \n",
       "2  [[(313.9878787878788, 384.1294236602629), (339...        []   \n",
       "3                                                 []       [2]   \n",
       "4  [[(203.37777777777777, 235.99198396793588), (1...        []   \n",
       "\n",
       "                                        polygons_pan       more_features  \n",
       "0  [[(228.0551181102362, 277.6509186351706), (231...  [0, 0, 1, 0, 1, 0]  \n",
       "1  [[(263.552, 259.584), (316.032, 237.056), (344...  [1, 0, 0, 0, 1, 0]  \n",
       "2                                                 []  [1, 0, 0, 0, 1, 0]  \n",
       "3  [[(246.784, 171.17866666666666), (283.648, 156...  [1, 0, 0, 0, 1, 0]  \n",
       "4                                                 []  [0, 0, 0, 1, 0, 1]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>nr_boil</th>\n",
       "      <th>polygons_boil</th>\n",
       "      <th>nr_pan</th>\n",
       "      <th>polygons_pan</th>\n",
       "      <th>more_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDIyeJf</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[(184.32, 243.712), (201.728, 193.87733333333...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDIuxfUrw8kOOu4DI</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[(227.456, 202.752), (257.408, 163.328), (289...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDGYlhoJdU</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[[(192.256, 225.28), (224.256, 230.4), (220.54...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IDUpWDxrBZj</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[[(266.82910321489004, 288.89385474860336), (2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDOaq1s</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[[(355.6848484848485, 156.86147623862487), (36...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_id nr_boil  \\\n",
       "0            IDIyeJf      []   \n",
       "1  IDIuxfUrw8kOOu4DI      []   \n",
       "2         IDGYlhoJdU      []   \n",
       "3        IDUpWDxrBZj  [1, 1]   \n",
       "4            IDOaq1s     [1]   \n",
       "\n",
       "                                       polygons_boil  nr_pan  \\\n",
       "0                                                 []     [1]   \n",
       "1                                                 []     [1]   \n",
       "2                                                 []  [2, 1]   \n",
       "3  [[(266.82910321489004, 288.89385474860336), (2...      []   \n",
       "4  [[(355.6848484848485, 156.86147623862487), (36...      []   \n",
       "\n",
       "                                        polygons_pan       more_features  \n",
       "0  [[(184.32, 243.712), (201.728, 193.87733333333...  [1, 0, 0, 0, 1, 0]  \n",
       "1  [[(227.456, 202.752), (257.408, 163.328), (289...  [1, 0, 0, 0, 1, 0]  \n",
       "2  [[(192.256, 225.28), (224.256, 230.4), (220.54...  [1, 0, 0, 0, 1, 0]  \n",
       "3                                                 []  [0, 0, 0, 1, 0, 1]  \n",
       "4                                                 []  [1, 0, 0, 0, 1, 0]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"ModelBuild/model08_yoloJ/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNetB0 without the top layer\n",
    "effnet = EfficientNetB5(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,       # Random rotation range in degrees\n",
    "    width_shift_range=0.2,   # Random horizontal shift\n",
    "    height_shift_range=0.2,  # Random vertical shift\n",
    "    shear_range=0.2,         # Random shear transformation\n",
    "    horizontal_flip=True,    # Random horizontal flip\n",
    "    fill_mode='nearest',      # How to fill in newly created pixels (nearest pixel)\n",
    "    brightness_range=[0.2, 1.8],\n",
    "    \n",
    ")\n",
    "\n",
    "# Function to extract features from an image\n",
    "def extract_image_features(image_path):\n",
    "\n",
    "    image_path = \"images/\" + image_path + \".jpg\"\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (456, 456))\n",
    "    img = preprocess_input(img)  # Normalize image\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    augmented_img = datagen.random_transform(img[0].copy())\n",
    "    augmented_img = np.expand_dims(augmented_img, axis=0)  # Add batch dimension\n",
    "\n",
    "\n",
    "    features = effnet.predict(augmented_img, verbose=0)  # Extract features\n",
    "    return features.flatten()  # Convert to 1D\n",
    "\n",
    "\n",
    "# bypass waiting time\n",
    "import pickle\n",
    "with open('ModelBuild/model06_data.pkl', 'rb') as f:\n",
    "    a = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = a[\"X_train\"]\n",
    "X_val = a[\"X_val\"]\n",
    "y_train = a[\"y_train\"]\n",
    "y_val = a[\"y_val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_yolo_features(df, path, image_col = \"img_id\"):\n",
    "    yolo_features = []\n",
    "    for i, row in df.iterrows():\n",
    "        if i % 100 == 0:\n",
    "            print(i, len(df))\n",
    "\n",
    "        #resize_image(row[\"ID\"])\n",
    "        results = model(f\"{path}/{row[image_col]}.png\", verbose=False)\n",
    "        result = results[0]\n",
    "\n",
    "        class_counts = {}\n",
    "\n",
    "        for cls in result.boxes.cls.tolist():\n",
    "            class_counts[int(cls)] = class_counts.get(int(cls), 0) + 1\n",
    "\n",
    "        class_names = model.names\n",
    "        named_counts = {class_names[k]: v for k, v in class_counts.items()}\n",
    "\n",
    "        if \"boil_alone\" in named_counts:\n",
    "            boils = named_counts[\"boil_alone\"]\n",
    "        else:\n",
    "            boils = 0\n",
    "        \n",
    "        if \"pan_alone\" in named_counts:\n",
    "            pans = named_counts[\"pan_alone\"]\n",
    "        else:\n",
    "            pans = 0\n",
    "\n",
    "        yolo_features.append([boils, pans])\n",
    "    \n",
    "    df[\"yolo_features\"] = yolo_features\n",
    "\n",
    "#extract_yolo_features(df_val, \"ModelBuild/model08/val/images\")\n",
    "#extract_yolo_features(df_train, \"ModelBuild/model08/train/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>nr_boil</th>\n",
       "      <th>polygons_boil</th>\n",
       "      <th>nr_pan</th>\n",
       "      <th>polygons_pan</th>\n",
       "      <th>more_features</th>\n",
       "      <th>yolo_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IDUXSjTNlUQ59</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[14, 16]</td>\n",
       "      <td>[[(228.0551181102362, 277.6509186351706), (231...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_id nr_boil polygons_boil    nr_pan  \\\n",
       "0  IDUXSjTNlUQ59      []            []  [14, 16]   \n",
       "\n",
       "                                        polygons_pan       more_features  \\\n",
       "0  [[(228.0551181102362, 277.6509186351706), (231...  [0, 0, 1, 0, 1, 0]   \n",
       "\n",
       "  yolo_features  \n",
       "0        [0, 1]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#df_train.to_pickle(\"ModelBuild/model10/Model_Train.pkl\")\n",
    "#df_val.to_pickle(\"ModelBuild/model10/Model_Val.pkl\")\n",
    "\n",
    "df_train = pd.read_pickle(\"ModelBuild/model10/Model_Train.pkl\")\n",
    "df_val = pd.read_pickle(\"ModelBuild/model10/Model_Val.pkl\")\n",
    "\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[[\"more_features\", \"yolo_features\"]]\n",
    "X_train = np.array([row[\"more_features\"] + row[\"yolo_features\"] for i, row in X_train.iterrows()])\n",
    "y_train = df_train[[\"nr_boil\", \"nr_pan\"]]\n",
    "y_train = np.array([ [sum(row[\"nr_boil\"]) , sum(row[\"nr_pan\"])] for i, row in y_train.iterrows()])\n",
    "\n",
    "X_val = df_val[[\"more_features\", \"yolo_features\"]]\n",
    "X_val = np.array([row[\"more_features\"] + row[\"yolo_features\"] for i, row in X_val.iterrows()])\n",
    "y_val = df_val[[\"nr_boil\", \"nr_pan\"]]\n",
    "y_val = np.array([ [sum(row[\"nr_boil\"]) , sum(row[\"nr_pan\"])] for i, row in y_val.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 10 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    from .memory import Memory\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/memory.py\", line 12, in <module>\n",
      "    __import__(pkg_name)\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/__init__.py\", line 114, in <module>\n",
      "    from .memory import Memory\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/memory.py\", line 12, in <module>\n",
      "    import asyncio\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/asyncio/__init__.py\", line 8, in <module>\n",
      "    from .base_events import *\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/asyncio/base_events.py\", line 23, in <module>\n",
      "    import asyncio\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/asyncio/__init__.py\", line 8, in <module>\n",
      "    from .base_events import *\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/asyncio/base_events.py\", line 25, in <module>\n",
      "    import subprocess\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "    import socket\n",
      "  File \"/opt/anaconda3/envs/CAA01/lib/python3.10/socket.py\", line 51, in <module>\n",
      "    import _socket\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 5. Run RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m     16\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(xgb_regressor, param_distributions\u001b[38;5;241m=\u001b[39mparam_dist, \n\u001b[1;32m     17\u001b[0m                                    n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                    cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/CAA01/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_regressor = MultiOutputRegressor(xgb.XGBRegressor(objective=\"reg:squarederror\",\n",
    "                                                      random_state=42))\n",
    "\n",
    "param_dist = {\n",
    "    \"estimator__n_estimators\": [100, 300, 500, 700],  # More trees improve results\n",
    "    \"estimator__learning_rate\": [0.005, 0.01, 0.05],  # Lower LR prevents overfitting\n",
    "    \"estimator__max_depth\": [3, 5, 7],  # Limit tree depth for large feature sets\n",
    "    \"estimator__subsample\": [0.4, 0.5, 0.7, 0.9],  # Row sampling\n",
    "    \"estimator__colsample_bytree\": [0.3, 0.5, 0.6],  # Feature sampling (important for 2K features)\n",
    "    \"estimator__reg_lambda\": [5, 10, 20, 50],  # L2 Regularization\n",
    "    \"estimator__reg_alpha\": [5, 10, 50],  # L1 Regularization\n",
    "    \"estimator__gamma\": [0, 0.1, 0.2, 0.5],  # Controls tree split sensitivity\n",
    "}\n",
    "\n",
    "# 5. Run RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(xgb_regressor, param_distributions=param_dist, \n",
    "                                   n_iter=10, scoring=\"neg_mean_absolute_error\",\n",
    "                                   cv=7, verbose=2, n_jobs=-1, random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__subsample': 0.7,\n",
       " 'estimator__reg_lambda': 20,\n",
       " 'estimator__reg_alpha': 5,\n",
       " 'estimator__n_estimators': 15,\n",
       " 'estimator__max_depth': 5,\n",
       " 'estimator__learning_rate': 0.05,\n",
       " 'estimator__gamma': 0.5,\n",
       " 'estimator__colsample_bytree': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = random_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 2.2065573770491804\n",
      "Train MAE: 1.9368593685936861\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_val)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "y_pred = best_model.predict(X_train)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f\"Train MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"zindi_files/SampleSubmission.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "\n",
    "def hot_encod_img_placement(df):\n",
    "    extra_features_all = []\n",
    "    for i, row in df.iterrows():\n",
    "        extra_features = []\n",
    "        if row[\"placement\"] == \"roof\":\n",
    "            extra_features += [1, 0, 0, 0]\n",
    "        elif row[\"placement\"] == \"r_openspace\":\n",
    "            extra_features += [0, 1, 0, 0]\n",
    "        elif row[\"placement\"] == \"openspace\":\n",
    "            extra_features += [0, 0, 1, 0]\n",
    "        elif row[\"placement\"] == \"S-unknown\":\n",
    "            extra_features += [0, 0, 0, 1]\n",
    "        else:\n",
    "            extra_features += [0, 0, 0, 0]\n",
    "        if row[\"img_origin\"] == \"D\":\n",
    "            extra_features += [1, 0]\n",
    "        elif row[\"img_origin\"] == \"S\":\n",
    "            extra_features += [0, 1]\n",
    "        else:\n",
    "            extra_features += [0, 0] \n",
    "        extra_features_all.append(extra_features)\n",
    "    \n",
    "    df[\"more_features\"] = extra_features_all\n",
    "\n",
    "    df.drop(columns=[\"img_origin\"], inplace=True)\n",
    "    df.drop(columns=[\"placement\"], inplace=True)\n",
    "\n",
    "#hot_encod_img_placement(test)\n",
    "#extract_yolo_features(test, \"ModelBuild/model08_subm\", image_col = \"ID\")\n",
    "#test.to_pickle(\"ModelBuild/model10/Test.pkl\")\n",
    "test = pd.read_pickle(\"ModelBuild/model10/Test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>more_features</th>\n",
       "      <th>yolo_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00qprY</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID01AciUc</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID0328D</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID05WxObCFTs9</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID06AdCmLMlkO</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>IDzhpdPHeGHlmWEIx</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>IDztljx</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>IDzwPcyO0e</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1]</td>\n",
       "      <td>[8, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>IDzzNegz</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>IDzzZcEYNVZMCk</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1107 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID       more_features yolo_features\n",
       "0              ID00qprY  [1, 0, 0, 0, 1, 0]        [0, 1]\n",
       "1             ID01AciUc  [1, 0, 0, 0, 1, 0]        [0, 1]\n",
       "2               ID0328D  [1, 0, 0, 0, 1, 0]        [0, 2]\n",
       "3         ID05WxObCFTs9  [1, 0, 0, 0, 1, 0]        [0, 2]\n",
       "4         ID06AdCmLMlkO  [0, 0, 0, 1, 0, 1]        [1, 0]\n",
       "...                 ...                 ...           ...\n",
       "1102  IDzhpdPHeGHlmWEIx  [1, 0, 0, 0, 1, 0]        [0, 1]\n",
       "1103            IDztljx  [1, 0, 0, 0, 1, 0]        [0, 1]\n",
       "1104         IDzwPcyO0e  [0, 0, 0, 1, 0, 1]        [8, 1]\n",
       "1105           IDzzNegz  [1, 0, 0, 0, 1, 0]        [0, 1]\n",
       "1106     IDzzZcEYNVZMCk  [1, 0, 0, 0, 1, 0]        [0, 3]\n",
       "\n",
       "[1107 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[[\"more_features\", \"yolo_features\"]]\n",
    "X_test = np.array([row[\"more_features\"] + row[\"yolo_features\"] for i, row in X_test.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 2],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 8, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/96b_h5gn3y33k0c7jsvrstmm0000gn/T/ipykernel_86472/4204815357.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11831264197826385' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  submission.loc[submission[\"ID\"] == f\"{row['ID']}_boil\", \"Target\"] = pred[i][0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00qprY_boil</td>\n",
       "      <td>0.118313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00qprY_pan</td>\n",
       "      <td>3.117506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID01AciUc_boil</td>\n",
       "      <td>0.118313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID01AciUc_pan</td>\n",
       "      <td>3.117506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID0328D_boil</td>\n",
       "      <td>0.118313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID    Target\n",
       "0   ID00qprY_boil  0.118313\n",
       "1    ID00qprY_pan  3.117506\n",
       "2  ID01AciUc_boil  0.118313\n",
       "3   ID01AciUc_pan  3.117506\n",
       "4    ID0328D_boil  0.118313"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_model.predict(X_test)\n",
    "for i, row in test.iterrows():\n",
    "    submission.loc[submission[\"ID\"] == f\"{row['ID']}_boil\", \"Target\"] = pred[i][0]\n",
    "    submission.loc[submission[\"ID\"] == f\"{row['ID']}_pan\", \"Target\"] = pred[i][1]\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"zindi_files/model10_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAA01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
