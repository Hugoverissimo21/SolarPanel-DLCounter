{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# primeiro modelo: modelo 02 com randomsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader  # <-- Import Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tqdm as tqdm\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_multi_class_mask(image_size, polygons_boil, polygons_pan):\n",
    "    \"\"\"\n",
    "    Create a multi-class segmentation mask where:\n",
    "    - Boilers (nr_boil) are labeled as 0\n",
    "    - Photovoltaics (nr_pan) are labeled as 1\n",
    "    \"\"\"\n",
    "    mask = np.full(image_size, 1, dtype=np.uint8)  # Default background is now 1 (Photovoltaic)\n",
    "    \n",
    "    # Draw boiler panels with label 0\n",
    "    for polygon in polygons_boil:\n",
    "        cv2.fillPoly(mask, np.array([polygon], dtype=np.int32), 0)\n",
    "\n",
    "    # Draw photovoltaic panels with label 1\n",
    "    for polygon in polygons_pan:\n",
    "        cv2.fillPoly(mask, np.array([polygon], dtype=np.int32), 1)\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('Model_Train.pkl')\n",
    "df_val = pd.read_pickle('Model_Val.pkl')\n",
    "\n",
    "# Albumentations transformation pipeline (same for image & mask)\n",
    "albumentations_transform = A.Compose([\n",
    "    A.Resize(256, 256),  # Resize both image & mask\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.GaussianBlur(p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalize for DeepLabV3+\n",
    "    ToTensorV2(),  # Convert to float tensor\n",
    "])\n",
    "\n",
    "class SolarPanelDataset(Dataset):\n",
    "    def __init__(self, metadata_df, image_dir, transform=None, mask_size=(512, 512)):\n",
    "        self.metadata = metadata_df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.mask_size = mask_size  # Target size for masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        img_path = f\"{self.image_dir}/{row['img_id']}.jpg\"\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        # Ensure the mask is created with the same size as the image\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        mask = create_multi_class_mask((img_height, img_width), row['polygons_boil'], row['polygons_pan'])\n",
    "        mask = np.array(mask, dtype=np.uint8)  # Ensure mask is a NumPy array\n",
    "\n",
    "        # Apply Albumentations transformations\n",
    "        augmented = self.transform(image=image, mask=mask)\n",
    "        image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        # Convert mask to long tensor (class labels)\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Define image directory\n",
    "image_dir = \"/Users/joaop.cardoso/MestradoCD/CAA/Project 1/images\"\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = SolarPanelDataset(df_train, image_dir, transform=albumentations_transform)\n",
    "val_dataset = SolarPanelDataset(df_val, image_dir, transform=A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalize for DeepLabV3+\n",
    "    ToTensorV2()\n",
    "]))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3Plus(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3-5): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7-9): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11-15): 5 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17-21): 5 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23-29): 7 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=1632, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1632, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2688, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.4, inplace=False)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (decoder): DeepLabV3PlusDecoder(\n",
       "    (aspp): Sequential(\n",
       "      (0): ASPP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=448, bias=False)\n",
       "              (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=448, bias=False)\n",
       "              (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (3): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=448, bias=False)\n",
       "              (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (4): ASPPPooling(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SeparableConv2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): SeparableConv2d(\n",
       "        (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
       "        (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Load DeepLabV3+ with EfficientNet backbone\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"efficientnet-b4\",  # Choose EfficientNet-B4 as backbone\n",
    "    encoder_weights=\"imagenet\",  # Use pretrained ImageNet weights\n",
    "    in_channels=3,  # RGB images\n",
    "    classes=2  # Boiler (0), Photovoltaic (1)\n",
    ")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaop.cardoso/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Add dropout before classifier\n",
    "model.segmentation_head[0] = nn.Sequential(\n",
    "    nn.Dropout(0.3),  # 30% dropout\n",
    "    model.segmentation_head[0]\n",
    ")\n",
    "\n",
    "# Loss function (CrossEntropy for multi-class segmentation)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam optimizer with learning rate scheduling\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong signs of overfitting\n",
    "\n",
    "Next strategy:\n",
    "- Use RandomSearch with *patience* to find the best hyperparameters\n",
    "- Use early stopping to avoid overfitting\n",
    "\n",
    "Second model\n",
    "- Cancelled the hyperparameter fine tuning, would take way too long\n",
    "- Dumped the third class (background), only working with the two classes that have panels\n",
    "\n",
    "Third model\n",
    "- Increase polygons area to train YOLO model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Training:   0%|          | 0/610 [00:00<?, ?it/s]/var/folders/kl/mfb9z6_d1290hf_1b38hg6zr0000gn/T/ipykernel_31794/3984754472.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(mask, dtype=torch.long)\n",
      "Epoch 1/20 Training: 100%|██████████| 610/610 [42:55<00:00,  4.22s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:06<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 1/20\n",
      "   📉 Train Loss: 0.0672 | 🏆 Train IoU: 0.4629\n",
      "   📉 Val Loss: 0.0826 | 🏆 Val IoU: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Training: 100%|██████████| 610/610 [43:16<00:00,  4.26s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:10<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 2/20\n",
      "   📉 Train Loss: 0.0126 | 🏆 Train IoU: 0.5008\n",
      "   📉 Val Loss: 0.0343 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Training: 100%|██████████| 610/610 [43:15<00:00,  4.25s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:15<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 3/20\n",
      "   📉 Train Loss: 0.0065 | 🏆 Train IoU: 0.5230\n",
      "   📉 Val Loss: 0.0208 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Training: 100%|██████████| 610/610 [45:17<00:00,  4.46s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:20<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 4/20\n",
      "   📉 Train Loss: 0.0045 | 🏆 Train IoU: 0.5394\n",
      "   📉 Val Loss: 0.0150 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Training: 100%|██████████| 610/610 [46:25<00:00,  4.57s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:22<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 5/20\n",
      "   📉 Train Loss: 0.0036 | 🏆 Train IoU: 0.5870\n",
      "   📉 Val Loss: 0.0129 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 Training: 100%|██████████| 610/610 [46:48<00:00,  4.60s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:15<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 6/20\n",
      "   📉 Train Loss: 0.0032 | 🏆 Train IoU: 0.6075\n",
      "   📉 Val Loss: 0.0124 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 Training: 100%|██████████| 610/610 [46:11<00:00,  4.54s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:16<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 7/20\n",
      "   📉 Train Loss: 0.0028 | 🏆 Train IoU: 0.6370\n",
      "   📉 Val Loss: 0.0105 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 Training: 100%|██████████| 610/610 [44:56<00:00,  4.42s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:07<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 8/20\n",
      "   📉 Train Loss: 0.0026 | 🏆 Train IoU: 0.6427\n",
      "   📉 Val Loss: 0.0128 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 Training: 100%|██████████| 610/610 [43:11<00:00,  4.25s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:14<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 9/20\n",
      "   📉 Train Loss: 0.0024 | 🏆 Train IoU: 0.6681\n",
      "   📉 Val Loss: 0.0099 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 Training: 100%|██████████| 610/610 [42:48<00:00,  4.21s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:10<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 10/20\n",
      "   📉 Train Loss: 0.0023 | 🏆 Train IoU: 0.6763\n",
      "   📉 Val Loss: 0.0082 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 Training: 100%|██████████| 610/610 [43:56<00:00,  4.32s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:31<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 11/20\n",
      "   📉 Train Loss: 0.0022 | 🏆 Train IoU: 0.6903\n",
      "   📉 Val Loss: 0.0101 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 Training: 100%|██████████| 610/610 [44:00<00:00,  4.33s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:12<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 12/20\n",
      "   📉 Train Loss: 0.0021 | 🏆 Train IoU: 0.6985\n",
      "   📉 Val Loss: 0.0078 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 Training: 100%|██████████| 610/610 [42:32<00:00,  4.18s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:11<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 13/20\n",
      "   📉 Train Loss: 0.0020 | 🏆 Train IoU: 0.7018\n",
      "   📉 Val Loss: 0.0077 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 Training: 100%|██████████| 610/610 [42:36<00:00,  4.19s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:12<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 14/20\n",
      "   📉 Train Loss: 0.0020 | 🏆 Train IoU: 0.7165\n",
      "   📉 Val Loss: 0.0069 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 Training: 100%|██████████| 610/610 [42:39<00:00,  4.20s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:12<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 15/20\n",
      "   📉 Train Loss: 0.0019 | 🏆 Train IoU: 0.7133\n",
      "   📉 Val Loss: 0.0070 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 Training: 100%|██████████| 610/610 [46:14<00:00,  4.55s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:18<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 16/20\n",
      "   📉 Train Loss: 0.0019 | 🏆 Train IoU: 0.7198\n",
      "   📉 Val Loss: 0.0072 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 Training: 100%|██████████| 610/610 [45:32<00:00,  4.48s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:16<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Best Model Saved!\n",
      "\n",
      "🔹 Epoch 17/20\n",
      "   📉 Train Loss: 0.0018 | 🏆 Train IoU: 0.7436\n",
      "   📉 Val Loss: 0.0065 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 Training: 100%|██████████| 610/610 [45:23<00:00,  4.47s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:18<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 18/20\n",
      "   📉 Train Loss: 0.0018 | 🏆 Train IoU: 0.7354\n",
      "   📉 Val Loss: 0.0066 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 Training: 100%|██████████| 610/610 [44:55<00:00,  4.42s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:18<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 19/20\n",
      "   📉 Train Loss: 0.0018 | 🏆 Train IoU: 0.7370\n",
      "   📉 Val Loss: 0.0066 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 Training: 100%|██████████| 610/610 [43:58<00:00,  4.33s/it]\n",
      "Validation: 100%|██████████| 153/153 [04:11<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Epoch 20/20\n",
      "   📉 Train Loss: 0.0017 | 🏆 Train IoU: 0.7256\n",
      "   📉 Val Loss: 0.0076 | 🏆 Val IoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def iou_score(preds, labels, num_classes=2):\n",
    "    \"\"\"Compute IoU (Intersection over Union) for multi-class segmentation.\"\"\"\n",
    "    preds = torch.argmax(preds, dim=1)  # Convert logits to class predictions\n",
    "    iou = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((preds == cls) & (labels == cls)).sum().item()\n",
    "        union = ((preds == cls) | (labels == cls)).sum().item()\n",
    "        if union == 0:\n",
    "            iou.append(float('nan'))\n",
    "        else:\n",
    "            iou.append(intersection / union)\n",
    "\n",
    "    return np.nanmean(iou)  # Ignore NaNs if a class is missing in batch\n",
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float(\"inf\")\n",
    "accumulation_steps = 4  # Simulate larger batch size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    optimizer.zero_grad()  # Initialize gradients before accumulation\n",
    "\n",
    "    # Training Loop\n",
    "    for i, (images, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\")):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, masks)  # Compute loss\n",
    "        loss = loss / accumulation_steps  # Normalize loss by accumulation steps\n",
    "\n",
    "        loss.backward()  # Accumulate gradients\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:  # Update model weights every accumulation_steps\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_iou += iou_score(outputs, masks, num_classes=2)\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = running_loss / num_batches\n",
    "    avg_train_iou = total_iou / num_batches\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_iou += iou_score(outputs, masks, num_classes=2)\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_val_loss = val_loss / num_batches\n",
    "    avg_val_iou = val_iou / num_batches\n",
    "\n",
    "    # Save Best Model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), f\"best_model_effnet_deepl_epoch{epoch}.pth\")\n",
    "        print(\"🔥 Best Model Saved!\")\n",
    "\n",
    "    print(f\"\\n🔹 Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"   📉 Train Loss: {avg_train_loss:.4f} | 🏆 Train IoU: {avg_train_iou:.4f}\")\n",
    "    print(f\"   📉 Val Loss: {avg_val_loss:.4f} | 🏆 Val IoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_val_loss)  # Use ReduceLROnPlateau correctly\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
