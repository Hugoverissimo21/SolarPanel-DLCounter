
\documentclass[conference]{IEEEtran}

\usepackage{float} 
\usepackage{url}  
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{cite}
\pagestyle{plain}
\usepackage{amsmath}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning}
\usepackage{placeins}


\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
\fi

\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}


\title{Lacuna Solar Survey Challenge: Counting Photovoltaic and Solar Panels from Aerial Imagery}

\author{\IEEEauthorblockN{\\ Hugo Veríssimo}
\IEEEauthorblockA{Complements of Machine Learning 24/25\\
University of Aveiro\\
Aveiro, Portugal\\
hugoverissimo@ua.pt}
\and
\IEEEauthorblockN{\\ João Cardoso}
\IEEEauthorblockA{Complements of Machine Learning 24/25\\
University of Aveiro\\
Aveiro, Portugal\\
joaopcardoso@ua.pt}}

\maketitle
\thispagestyle{plain}

\begin{abstract}
abstact
\end{abstract}

\begin{quote}
\small
\noindent
\textbf{Keywords:} EfficientNet, Object Detection
\end{quote}

\IEEEpeerreviewmaketitle


\section{Introduction}

Access to electricity and warm water is a basic necessity nowadays. In developing countries, the lack of a centralized distribution system makes this access harder for everyone. To improve on this gap, it is essential for governments, non-governmental organizations, and energy suppliers to understand how solar and solar thermal panels (for electricity and water heating, respectively) are distributed throughout the territory to ensure proper planning and effective policy making. In this context, a challenge was created by the Lacuna Fund and associate entities in the Zindi platform to develop a machine learning model capable of accurately detecting and counting the number of solar thermal (solar from here on) and photovoltaic panels in drone and satellite imagery.

In the present work, we have developed different approaches to the problem, where the two types of panels are considered in isolation: taking a regression type approach, where images are analysed as a whole and the target number of panels are provided per image; by identifying the panels through object detection and counting them afterwards; and by applying segmentation models to identify the regions of interest, analysing them and counting the panels.

%EXPLICAR E FICAR BEM EXPLICITO: DUAS REGRESSOES: pan E boil

\section{state of the art?}

\subsection{EfficientNetV2}

\subsection{Object Detection}

\subsection{Segmentation models}
asdasdas

\section{Methodology}.

\subsection{Data description (com EDA)}

o dados, fornecidos pela propria competicao (citar), consistem em 4419 imagens, complementadas por metadata referente à origin da imagem e ao placement dos paineis, providing context on installation environments.

da totalidade destas imagens, 3312 (75\%) contêm indicacoes das delimitacoes de conjutnos de paineis e de boilers, atraves de poligonos, assim como a quantidade que se encontra dentro de cada qual. as restantes 1107 (25\%) nao têm esta informacao. Assim, por opcao da competicao, temos uma distribuicao de treino e teste de 75/25

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_origin_classes.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_origin_classes}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_placement_classes.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_placement_classes}
\end{figure}

nas figuras \ref{fig:data_origin_classes} e \ref{fig:data_placement_classes} podem-se observar as classes de origin e de placement relativas as imagens. as origins da imagem podem ser drone image (D) or satellite image (S), while the placement classes (Installations) sao distribuidas por on rooftops or terraces (roof), satellite images where the specific placement could not be determined (S-unknown), in open courtyards or gardens (openspace), that span both rooftops and outdoor spaces (r\_openspace).


\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_distribution.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_distribution}
\end{figure}

ademais, é também importante referir uma presença em maior peso de panels face ao numero de boilers, como se verifica na figura \ref{fig:data_distribution}

tendo em conta os poligonos referentes aos panels e boilers, também foi analisada a distribuicao da quantidade de paineis e de boilers naos poligonos que delimitam os conjuntos.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_boil_distribution.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_boil_distribution}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_panel_distribution.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_panel_distribution}
\end{figure}

as figuras \ref{fig:data_boil_distribution} e \ref{fig:data_panel_distribution} revelam esta distribuicao, revelando que .... (fiquei sem inspiracao)


\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_segmentation_mask.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_segmentation_mask}
\end{figure}

por fim, na imagem \ref{fig:data_segmentation_mask} pode-se verificar uma das imagens de treino e os respetivos poligonos referentes aos paineis e boilers convertidos numa mascara de segmentacao, onde se verifica a presença de 4 grupos de solar panels, sendo cada um destes um grupo unitário, e 1 grupo de boilers, tambem unitario.


\subsection{data: pre processamento e ques}

atraves de algumas discussoes do forum da competicao, uma analise mais aprofundada de algumas imagens aleator e dos dados de treino, foram verficados alguns obstaculos para a aplicacao dos modelos.

nomeadamente, haviam linhas por poligono ao inves de linhas por imagem, as coordenadas dos poligonos eram strings ao inves de floats e algumas coordenadas tinham letras pelo meio.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/data_poly_problems.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:data_poly_problems}
\end{figure}

apos estas correções, uma das dificuldades tornou-se a validade dos poligonos. alguns poligonos tinham deslocacoes em relacao a posicao real dos paineis, outros tinham vertices misaligned, como se pode ver na imagem \ref{fig:data_poly_problems} alguns exemplos. apesar de não ser um erro o excessive object inclusion, esta torna-se uma barreira a aplicacao direta de modelos como o yolo, que requerem uma mascara por objeto unitario.

de modo a combtaer a validade dos poligonos, foi efetuada uma revisao manual de cada qual, envelvendo a correcao de alguns poligonos deslocados e a eliminacao de imagens com poligonos misaligned.

% https://zindi.africa/competitions/lacuna-solar-survey-challenge/discussions/25548
% GAJO QUE AJUDOU COM O ACETRTAR OS POLYGONS REFERENCIAR ?

com este processo foram perdidaas apenas 263 imagens de treino.

%por fim, foi criado um dataset de validacao a partir do de treino, tendo esta divisao sido feita numa proporcao de 80/20

para alem disso, interessa também referir, que foi realizada data augmentation, nao como um processo de pre processamento, mas de forma online, no treino de todos os modelos, com as trasnformacoes
HorizontalFlip
VerticalFlip
RandomRotate90
GaussianBlur
CLAHE
HueSaturationValue
Normalize (dizer q fizemos normalizcao dos pixeis)

% DIZEMOS QUE USAMOS SMP 512X512 ?




\subsection{Models implemented}

....




aaa


\section{djaisjd Models}

llalal


\subsection{Hybrid Model aka zulo40}

tendo em conta a metadata da imagem e a propria, foi criada uma familia de modelos que nao tinham em conta a mask.

esta familia de modelos teve como base o codigo? desenvolvimento por um dos utilizadores da competicao e posteriormente adaptado e melhorado por nos
% https://zindi.africa/competitions/lacuna-solar-survey-challenge/discussions/25675

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/nn.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:nn}
\end{figure}

a arquitetura? desta familia de modelos pode ser verificada na imagem \ref{fig:nn}, que consite num hybrid model de neural networks, ao usar um bacbone (transfer learning) para extrarir features da imagem (cnn's) e snn? para extrar features da metadata. de seguida, é usado um attention head para juntar todas estas features, da imagem e da metadata, para posteriormente obtermos o resultado da regressao

ademais, como backbone foi exprimentado um densenet121, efficientnetv2B3 e resnet101, através da divisao dos dados em treino e validacao e o uso de data augmentation nos dados de treino.

ao verificar o melhor desempenho pelo efnet, tanto no treino como validacao como teste, decisiu-se fazer um fine-tunning dos hyperparameters.

\begin{table}[H]
\centering
\caption{zulo40 type model hyp}
\label{parametroszulp}
\begin{tabular}{ll}
\toprule
\textbf{Hyperparameter} & \textbf{Possible Values} \\
\midrule
Batch Size conta? & $\{16, 32, 64\}$ \\
Optimizer & AdamW \\
Learning Rate & $[10^{-5}, 10^{-3}]$ \\
Dropout & $\{0.2, 0.3, 0.4\}$ \\
Scheduler & CosineAnnealingWarmRestarts \\
T\_0 & $\{3, 5, 7, 10\}$ \\
T\_mult & $\{1, 2, 3, 5\}$ \\
Loss & HuberLoss \\
$\delta$ & 1 \\
\bottomrule
\end{tabular}
\end{table}


na tabela \ref{parametroszulp} pode se verificar o espaco possivel de hyperparametros utilizado, tendo sido a escolha dos melhores baseada numa random search com o uso de cross-validation.

contudo esta cross validation não foi muito tipica devido aos elevados tempos de ajuste dos modelos. os dados de treino foram separados em 5 folds (80/20), mas cada conjunto de hyperparametros so foi ajustado 3 vezes, e não as tipicas 5 vezes.

de modo a escolher o melhor modelo usou-se o validation mae médio como métrica tendo sido o melhor conjunto de hyperparametros dado por ... meta06

para alem disso é tbm importante indicar o uso de: 

- juntar os modelos (3, pq sao 3 folds) e faz a media das previsoes

- Test-Time Augmentation (TTA), where the model makes multiple predictions on augmented versions of the same image (e.g., flipping, scaling, cropping). These predictions are later averaged to improve accuracy.

- o scheduler altera o learning rate e o paraetro de regularizacao

quanto aos resultados deste modelo ...

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{assets/model01_lc.png}
    \caption{CAPTION CAPTION CAPTION CAPTION CAPTION}
    \label{fig:model01_lc}
\end{figure}

a learning curve Fig. \ref{fig:model01_lc}.... é de notar q ela revela picos em certar epochs (porximo da 5, 15, 35) devido ao scheduler aumentar o parametro de regularizacao

para alem disso a mesma parou a epoch 66 por early stopping, sendo o criterio de paragem a melhor validation mae (ns se e early stopping pq n tem patience mas sim max de 75 epochs e dps escolher o melhor)

no signs of overffiting

\begin{table}[H]
\centering
\caption{Error metrics for the Hybrid Model, for the train and test set, along with the number of samples for each.}
\label{tab:model01_results}
\begin{tabular}{lccc}
\toprule
\textbf{Dataset} & \textbf{MAE} & \textbf{Support} \\
\midrule
Train Set & 0.5127 & 3312 \\
Test Set & 0.8434 & 1107 \\
\bottomrule
\end{tabular}
\end{table}

quanto as metricas de erro presentes na Table \ref{tab:model01_results}, apesar de so termos o MAE parece n haver sinais de overiffing pelas medidas serem semelhantes

\subsection{yolo}

ideia inicial era fazer segmentacao de conjuntos de paineis e de boilers e posteriormente com outro modelo fazer contagem

problema foi q o modelo ao reconhecer paineis invidivudais, mesmo em conjuntos identificava individuais, levando ao mau desempenho do modelo

surgiu a ideia de criar 4 classeS: boiler, panel, conjunto de boileres, conjunto de panels, so q devido ao class imbalance o modelo teve resultados nao satisfatorios o suficente

METER GRAFICO IMABALANCE

entao decidiu-se rever o dataset e separar manualmente os poligonos em paineis e boileres indivudais, deixando de existir grupos de paineis

o yolo apresentou assim mt melhores resultados, apesar da reducao da dimensao do dataset em termos de imagens mas aumento de amostras do que realmente sao paineis e boilers individuais


fazer ja learning curve ou correr de novo last yolo?

IDEIA: correr de novo o last yolo, mas mudar hyperparemtros (lernaring rate, adamw, etc.), a ver se temos uma solucao melhor



\section{faa02 ig}



\begin{table}[H]
\centering
\caption{Error metrics for the train and test set (CF-LR), along with the number of samples for each.}
\label{tab:model01_results}
\begin{tabular}{lccc}
\toprule
\textbf{Dataset} & \textbf{RMSE} & \textbf{MAE} & \textbf{Support} \\
\midrule
Train Set & 0.58842 & 0.44604 & 80668 \\
Test Set & 1.24037 & 0.90651 & 20168 \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion} 

https://zindi.africa/competitions/lacuna-solar-survey-challenge/discussions/25674

\subsection{Performance Metrics}

discussao


\section{Conclusion}

conc


\section*{Work Load}

Both authors contributed equally to the project.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}



