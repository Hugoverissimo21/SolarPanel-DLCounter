{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaop.cardoso/miniconda3/envs/fcd/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is using a different strategy:\n",
    "- The metadata was encoded onto the images via one hot encoding \n",
    "- Based on the 2 classes and 2 origins, the class balancing was attempted for the 4 classes during the albumentations step (although officially there are only 2 classes still, solar and boiler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create multi-class mask\n",
    "def create_multi_class_mask(image_size, polygons_boil, polygons_pan):\n",
    "    mask = np.full(image_size, 1, dtype=np.uint8)  # Default background is Photovoltaic (1)\n",
    "    \n",
    "    # Draw boiler panels (0)\n",
    "    for polygon in polygons_boil:\n",
    "        cv2.fillPoly(mask, np.array([polygon], dtype=np.int32), 0)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_pickle('Model_Train.pkl')\n",
    "df_val = pd.read_pickle('Model_Val.pkl')\n",
    "\n",
    "# One-hot encode metadata\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "metadata_encoded = encoder.fit_transform(df_train[['img_placement', 'img_origin']])\n",
    "\n",
    "# Define transformation pipelines\n",
    "albumentations_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.GaussianBlur(p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Dataset class\n",
    "class SolarPanelDataset(Dataset):\n",
    "    def __init__(self, metadata_df, image_dir, transform=None, mask_size=(512, 512), balance=False):\n",
    "        self.metadata = metadata_df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.mask_size = mask_size\n",
    "        self.balance = balance\n",
    "        \n",
    "        # One-hot encode metadata\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.encoded_metadata = self.encoder.fit_transform(self.metadata[['img_placement', 'img_origin']])\n",
    "        \n",
    "        # Create class labels for balancing\n",
    "        self.class_labels = self.metadata.apply(lambda row: f\"{row['img_origin']}_{'solar' if row['polygons_pan'] else 'boiler'}\", axis=1)\n",
    "        \n",
    "        # Compute class weights for balancing\n",
    "        if balance:\n",
    "            class_counts = Counter(self.class_labels)\n",
    "            self.weights = [1.0 / class_counts[label] for label in self.class_labels]\n",
    "        else:\n",
    "            self.weights = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        img_path = f\"{self.image_dir}/{row['img_id']}.jpg\"\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        # Create the mask\n",
    "        mask = create_multi_class_mask(image.shape[:2], row['polygons_boil'], row['polygons_pan'])\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "\n",
    "        # Apply transformations\n",
    "        augmented = self.transform(image=image, mask=mask)\n",
    "        image, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "        # Convert mask to long tensor\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "        # Get one-hot encoded metadata\n",
    "        metadata_vector = torch.tensor(self.encoded_metadata[idx], dtype=torch.float32)\n",
    "\n",
    "        return image, mask, metadata_vector  # Return metadata as additional input\n",
    "\n",
    "# Define image directory\n",
    "image_dir = \"/Users/joaop.cardoso/MestradoCD/CAA/Project 1/images\"\n",
    "\n",
    "# Create train dataset with class balancing\n",
    "train_dataset = SolarPanelDataset(df_train, image_dir, transform=albumentations_transform, balance=True)\n",
    "val_dataset = SolarPanelDataset(df_val, image_dir, transform=A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "]))\n",
    "\n",
    "# Create Weighted Sampler for class balancing\n",
    "if train_dataset.weights:\n",
    "    sampler = WeightedRandomSampler(weights=train_dataset.weights, num_samples=len(train_dataset), replacement=True)\n",
    "else:\n",
    "    sampler = None\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler if sampler else None, shuffle=sampler is None, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaop.cardoso/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/var/folders/kl/mfb9z6_d1290hf_1b38hg6zr0000gn/T/ipykernel_51075/2311934670.py:30: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/Users/joaop.cardoso/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load DeepLabV3+ with EfficientNet-B4 backbone\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"efficientnet-b4\",  # EfficientNet-B4 as the encoder\n",
    "    encoder_weights=\"imagenet\",  # Pretrained weights\n",
    "    in_channels=3,  # RGB images\n",
    "    classes=2  # Boiler (0), Photovoltaic (1)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Add dropout before the classifier correctly\n",
    "model.segmentation_head = nn.Sequential(\n",
    "    nn.Dropout(0.3),  # 30% dropout\n",
    "    model.segmentation_head\n",
    ")\n",
    "\n",
    "# Define loss function (CrossEntropy + Dice Loss for better performance)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "\n",
    "# Adam optimizer with weight decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# Mixed precision scaler for faster GPU training\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kl/mfb9z6_d1290hf_1b38hg6zr0000gn/T/ipykernel_51075/153856826.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/20 Training:   0%|          | 0/610 [00:00<?, ?it/s]/var/folders/kl/mfb9z6_d1290hf_1b38hg6zr0000gn/T/ipykernel_51075/4230360225.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(mask, dtype=torch.long)\n",
      "/var/folders/kl/mfb9z6_d1290hf_1b38hg6zr0000gn/T/ipykernel_51075/153856826.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # Enables mixed precision\n",
      "/Users/joaop.cardoso/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch 1/20 Training:   0%|          | 2/610 [01:02<5:18:06, 31.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, masks) \u001b[38;5;241m+\u001b[39m dice_loss(outputs, masks)  \u001b[38;5;66;03m# Combined loss\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Accumulate gradients\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# ðŸ”¹ Only update every `accumulation_steps`\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader):\n",
      "File \u001b[0;32m~/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m~/miniconda3/envs/fcd/lib/python3.12/site-packages/torch/autograd/function.py:292\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    This class is used for internal autograd work. Do not use.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m        Apply method used when executing this Node during the backward\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to calculate IoU\n",
    "def iou_score(preds, labels, num_classes=2):\n",
    "    \"\"\"Compute IoU (Intersection over Union) for multi-class segmentation.\"\"\"\n",
    "    preds = torch.argmax(preds, dim=1)  # Convert logits to class predictions\n",
    "    iou = []\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        intersection = ((preds == cls) & (labels == cls)).sum().item()\n",
    "        union = ((preds == cls) | (labels == cls)).sum().item()\n",
    "        if union == 0:\n",
    "            iou.append(float('nan'))\n",
    "        else:\n",
    "            iou.append(intersection / union)\n",
    "\n",
    "    return np.nanmean(iou)  # Ignore NaNs if a class is missing in batch\n",
    "\n",
    "\n",
    "# ðŸ”¹ Model Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=2\n",
    ").to(device)\n",
    "\n",
    "# ðŸ”¹ Add Dropout Correctly\n",
    "model.segmentation_head = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    model.segmentation_head\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Loss Functions (CrossEntropy + Dice Loss)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "\n",
    "# ðŸ”¹ Optimizer & LR Scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# ðŸ”¹ Mixed Precision (Speeds up Training)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training Hyperparameters\n",
    "num_epochs = 20\n",
    "best_val_loss = float(\"inf\")\n",
    "accumulation_steps = 4  # Simulates larger batch size\n",
    "\n",
    "# ðŸ”¹ Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    optimizer.zero_grad()  # Initialize gradients before accumulation\n",
    "\n",
    "    for i, (images, masks, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\")):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        with autocast():  # Enables mixed precision\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, masks) + dice_loss(outputs, masks)  # Combined loss\n",
    "        \n",
    "        scaler.scale(loss).backward()  # Accumulate gradients\n",
    "\n",
    "        # ðŸ”¹ Only update every `accumulation_steps`\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_iou += iou_score(outputs, masks, num_classes=2)\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_train_loss = running_loss / num_batches\n",
    "    avg_train_iou = total_iou / num_batches\n",
    "\n",
    "    # ðŸ”¹ Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks, _ in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            with autocast():  # Use mixed precision in inference\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks) + dice_loss(outputs, masks)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_iou += iou_score(outputs, masks, num_classes=2)\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_val_loss = val_loss / num_batches\n",
    "    avg_val_iou = val_iou / num_batches\n",
    "\n",
    "    # ðŸ”¥ Save Best Model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), f\"best_model_effnet_deepl_epoch{epoch}.pth\")\n",
    "        print(\"ðŸ”¥ Best Model Saved!\")\n",
    "\n",
    "    # ðŸ”¹ Logging\n",
    "    print(f\"\\nðŸ”¹ Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"   ðŸ“‰ Train Loss: {avg_train_loss:.4f} | ðŸ† Train IoU: {avg_train_iou:.4f}\")\n",
    "    print(f\"   ðŸ“‰ Val Loss: {avg_val_loss:.4f} | ðŸ† Val IoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "    # ðŸ”¹ Adjust LR based on Validation Loss\n",
    "    scheduler.step(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
